{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0645d927",
   "metadata": {},
   "source": [
    "This notebook will be used to extract events positions from the statsbomb dataset\n",
    "and use them as starting positions to evaluate a multiagent policy\n",
    "\n",
    "The focus will be on shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20323d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas is already installed.\n",
      "numpy is already installed.\n",
      "matplotlib is already installed.\n",
      "seaborn is already installed.\n",
      "networkx is already installed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\", \"networkx\"\n",
    "]\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installs a package using pip if it's not already installed.\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"{package} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Check and install missing packages\n",
    "for package in required_packages:\n",
    "    install_package(package)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76062749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "from matplotlib.patches import Arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4045dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsbombpy is already installed.\n"
     ]
    }
   ],
   "source": [
    "install_package(\"statsbombpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5f9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsbombpy import sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1523885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress the authentication warning\n",
    "import warnings\n",
    "from statsbombpy.api_client import NoAuthWarning\n",
    "warnings.simplefilter(\"ignore\", NoAuthWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0ee690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------\n",
      "Grand total across all comps/seasons: 3464 matches\n"
     ]
    }
   ],
   "source": [
    "# Load all competitions\n",
    "comps = sb.competitions()\n",
    "\n",
    "# Extract the numeric year from 'season_name' (e.g. \"2023/2024\" -> 2023)\n",
    "comps['season_year'] = comps['season_name'].str[:4].astype(int)\n",
    "\n",
    "# Sort competition ascending by'season_year'\n",
    "comps_sorted = comps.sort_values(by='season_year', ascending=True).reset_index(drop=True)\n",
    "\n",
    "all_matches_list = []\n",
    "total_matches = 0\n",
    "\n",
    "# Iterate over competitions in chronological order\n",
    "for idx, row in comps_sorted.iterrows():\n",
    "    cid = row['competition_id']\n",
    "    sid = row['season_id']\n",
    "    comp_name = row['competition_name']\n",
    "    season_name = row['season_name']\n",
    "    season_year = row['season_year']\n",
    "    \n",
    "    # Load matches for the competition + season\n",
    "    comp_matches = sb.matches(competition_id=cid, season_id=sid)\n",
    "    \n",
    "    # Sort by match_date ascending\n",
    "    comp_matches = comp_matches.sort_values(by='match_date', ascending=True)\n",
    "    \n",
    "    # Print matches in chronological order\n",
    "    match_count = 0\n",
    "    for m_idx, m_row in comp_matches.iterrows():\n",
    "        match_date = m_row['match_date']\n",
    "        home_team  = m_row['home_team']\n",
    "        away_team  = m_row['away_team']\n",
    "        home_score = m_row['home_score']\n",
    "        away_score = m_row['away_score']\n",
    "        \n",
    "        # Print each match line: date, home vs away, final score\n",
    "        match_count += 1\n",
    "\n",
    "    # Print the total number of matches for this competition + season\n",
    "    \n",
    "    # Accumulate into an overall total and list\n",
    "    total_matches += match_count\n",
    "    all_matches_list.append(comp_matches)\n",
    "\n",
    "# This will create a single DataFrame with all matches\n",
    "all_matches = pd.concat(all_matches_list, ignore_index=True)\n",
    "\n",
    "# Print the grand total of matches across all competitions/seasons\n",
    "print(\"\\n-------------------------------------------\")\n",
    "print(f\"Grand total across all comps/seasons: {total_matches} matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56cb853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Success! ---\n",
      "Total assists collected: 286\n"
     ]
    }
   ],
   "source": [
    "all_assists_list = []\n",
    "i = 0\n",
    "\n",
    "for match_id in all_matches['match_id']:\n",
    "    # Fetch events for the current match\n",
    "    events = sb.events(match_id=match_id)\n",
    "\n",
    "    # Check if the column exists and filter for assists\n",
    "    if 'pass_shot_assist' in events.columns:\n",
    "        assists = events[events['pass_shot_assist'] == True].copy()\n",
    "        \n",
    "        if not assists.empty:\n",
    "            i += 1\n",
    "            # Add the match_id column so you know which match the assist belongs to\n",
    "            assists['match_id'] = match_id\n",
    "            \n",
    "            # Append this match's assists to the list\n",
    "            all_assists_list.append(assists)\n",
    "\n",
    "    if i == 10: break\n",
    "\n",
    "# Concatenate everything into one single DataFrame\n",
    "if all_assists_list:\n",
    "    final_assists_df = pd.concat(all_assists_list, ignore_index=True)\n",
    "    print(\"--- Success! ---\")\n",
    "    print(f\"Total assists collected: {len(final_assists_df)}\")\n",
    "else:\n",
    "    print(\"No assists found in any of the matches.\")\n",
    "    final_assists_df = pd.DataFrame() # Return empty df to avoid errors later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7442f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [106.3, 27.4]\n",
       "1      [100.4, 39.7]\n",
       "2      [105.2, 50.8]\n",
       "3      [106.8, 29.5]\n",
       "4      [109.6, 32.3]\n",
       "           ...      \n",
       "281    [105.6, 31.4]\n",
       "282     [99.5, 42.5]\n",
       "283    [104.4, 31.7]\n",
       "284    [103.9, 28.6]\n",
       "285     [65.1, 37.2]\n",
       "Name: pass_end_location, Length: 286, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_assists_df.get('pass_end_location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2105a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [85.6, 11.1]\n",
       "1      [115.4, 70.1]\n",
       "2      [107.2, 66.5]\n",
       "3      [100.1, 42.7]\n",
       "4      [117.1, 24.1]\n",
       "           ...      \n",
       "281     [91.8, 39.6]\n",
       "282     [89.9, 56.8]\n",
       "283    [109.5, 39.1]\n",
       "284    [106.8, 21.8]\n",
       "285     [60.0, 40.0]\n",
       "Name: location, Length: 286, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_assists_df.get('location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414d7562",
   "metadata": {},
   "source": [
    "## Simulation with custom positions\n",
    "\n",
    "From the selected failed assists we select the start and end position to use them as the custom starting postions of the two attackers in the digital twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20d23530",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = final_assists_df.get('location')[0]\n",
    "a2 = final_assists_df.get('pass_end_location')[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
